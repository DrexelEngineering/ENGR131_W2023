{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activity 3: Determining the Superbowl Proposition Winner\n",
    "\n",
    "We made a Superbowl proposition game for ENGR131 now it is time to determine the winner. The submission are in an excel file your tasks is to calculate the winner. We have provided you a list with the correct outcomes from the superbowl. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load the File\n",
    "\n",
    "The file is named \"Super Bowl Propositions.xls\" load the file into a Pandas DataFrame. \n",
    "\n",
    "Save it as a variable df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in /home/jagar2/miniconda3/envs/ENGR_131/lib/python3.10/site-packages (3.1.0)\r\n",
      "Requirement already satisfied: et-xmlfile in /home/jagar2/miniconda3/envs/ENGR_131/lib/python3.10/site-packages (from openpyxl) (1.1.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ellipsis"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# use the pd.read_excel to load the excel file\n",
    "..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `df.head()` to look at the first few lines of the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ellipsis"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to get the strings for each of the questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "cannot assign to ellipsis (552610352.py, line 11)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[4], line 11\u001b[0;36m\u001b[0m\n\u001b[0;31m    for ... in ...:\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m cannot assign to ellipsis\n"
     ]
    }
   ],
   "source": [
    "# We want to extract the question names\n",
    "# To do this we want all the column heading that have a ? in the string\n",
    "\n",
    "# We can start by creating a empty list called questions\n",
    "...\n",
    "\n",
    "# now we want to loop around all of the row heading\n",
    "# You can build a loop that loops around each column name\n",
    "# The column name can be obtained from df.columns\n",
    "# save each heading in a temporary variable column\n",
    "for ... in ...:\n",
    "    \n",
    "    # Now we want to check if the variable column is a questions\n",
    "    # To do this we want to use an if statement that sees if a \"?\" is in the string\n",
    "    if ... in ...:\n",
    "        \n",
    "        # if this is true we want to add the heading to the list\n",
    "        # this can be done using the list method .append(obj)\n",
    "        # the obj is the local variable in the list\n",
    "        ...\n",
    "\n",
    "# if you want to check this you can print the columns        \n",
    "...    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to calculate the score. We have provided comments to help you complete this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Correct_Answers = ['Under 2 minutes 2 seconds (worth 1 point)', #1\n",
    " 'Tails (worth 1 point)', #2\n",
    " 'Yes (worth 1 point)', #3\n",
    " 'Yes (worth 1 point)', #4\n",
    " 'Run (worth 2 points)', #5\n",
    " 'Yes (worth 2 points)', #6\n",
    " 'Eagles (worth 2 points)', #7\n",
    " 'Chiefs (worth 2 points)', #8\n",
    " 'Jalen Hurts (worth 2 points)', #9\n",
    " 'Chiefs (worth 2 points)', #10\n",
    " 'Touchdown (worth 1 point)', #11\n",
    " 'Over 24.5 (worth 2 points)', #12\n",
    " 'Eagles (worth 2 points)', #13\n",
    " 'No (worth 2 points)', #14\n",
    " 'No (worth 2 points)', #15\n",
    " 'Eagles (worth 2 points)', #16\n",
    " 'Over 9.5 (worth 2 points)', #17\n",
    " 'Other (worth 2 points)', #18\n",
    " 'Under 2.5 (worth 1 point)', #19\n",
    " 'Under 281.5 (worth 2 points)', #20\n",
    " 'Over 241.5 (worth 2 points)', #21\n",
    " 'Over 78.5 (worth 2 points', #22\n",
    " 'Over 72.5 (worth 2 points)', #23\n",
    " 'Over 6.5 (worth 2 points)', #24\n",
    " 'Fourth Quarter (worth 2 points)', #25\n",
    " 'Third Quarter (worth 2 points)', #26\n",
    " 'Yes (worth 2 points)', #27\n",
    " 'Eagles (worth 2 points)', #28\n",
    " '3 (worth 2 points)', #29\n",
    " 'No (worth 3 points)', #30\n",
    " 'No (worth 1 point)', #31\n",
    " 'Odd (worth 1 point)', #32\n",
    " 'Purple (worth 6 points)', #33\n",
    " 'Odd (worth 2 points)', #34\n",
    " 'Over 50.5 (worth 3 points)', #35\n",
    " 'Patrick Mahomes (worth 1 point)', #36\n",
    " 'xxx'] #37\n",
    "\n",
    "points = [1, #1 'Under 2 minutes 2 seconds (worth 1 point)'\n",
    " 1, #2 'Tails (worth 1 point)'\n",
    " 1, #3  Yes (worth 1 point)\n",
    " 1, #4 Yes (worth 1 point)\n",
    " 2, #5 Run (worth 2 points)\n",
    " 2, #6 Yes (worth 2 points)\n",
    " 2, #7 Eagles (worth 2 points)\n",
    " 2, #8 Chiefs (worth 2 points)\n",
    " 2, #9 Jalen Hurts (worth 2 points)\n",
    " 2, # 10 Chiefs (worth 2 points)\n",
    " 1, # 11 Touchdown (worth 1 point)\n",
    " 2, #12 Over 24.5 (worth 2 points)\n",
    " 2, #13 Eagles (worth 2 points)\n",
    " 2, #14 No (worth 2 points)\n",
    " 2, #15 No (worth 2 points)\n",
    " 2, #16 Eagles (worth 2 points)\n",
    " 2, #17 Over 9.5 (worth 2 points)\n",
    " 2, #18 Other (worth 2 points)\n",
    " 1, #19 Under 2.5 (worth 1 point)\n",
    " 2, #20 Under 281.5 (worth 2 points)\n",
    " 2, #21 Over 241.5 (worth 2 points)\n",
    " 2, #22 Over 78.5 (worth 2 points\n",
    " 2, #23 Over 72.5 (worth 2 points)\n",
    " 2, #24 Over 6.5 (worth 2 points)\n",
    " 2, #25 Fourth Quarter (worth 2 points)\n",
    " 2, #26 Third Quarter (worth 2 points)\n",
    " 2, #27 Yes (worth 2 points)\n",
    " 2, #28 Eagles (worth 2 points)\n",
    " 2, #29 3 (worth 2 points)\n",
    " 3, #30 No (worth 3 points)\n",
    " 1, #31 No (worth 1 point)\n",
    " 1, #32 Odd (worth 1 point)\n",
    " 6, #33 Purple (worth 6 points)\n",
    " 2, #34 Odd (worth 2 points)\n",
    " 3, #35 Over 50.5 (worth 3 points)\n",
    " 1, # Patrick Mahomes (worth 1 point)\n",
    " 250]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a list to keep the scores\n",
    "...\n",
    "\n",
    "# create a loop that goes through each row\n",
    "# to turn the df into a row iterator use the .iterrows() method\n",
    "# You can select just the questions by indexing the dataframe with the list\n",
    "# example: df[questions].iterrows()\n",
    "# note iterrows returns a tuple with the first value being the index and the second being the row\n",
    "for ..., ... in ...:\n",
    "    \n",
    "    # initiate a score for the person\n",
    "    ...\n",
    "    \n",
    "    # Since we have the heading for all of the questions we can loop around the list\n",
    "    # The correct answers are order\n",
    "    # we also have an ordered list that shows how much each question is worth\n",
    "    # make a loop around the questions that uses enumerate\n",
    "    # enumerate will let you get the index number and the contents\n",
    "    for ..., ... in ...:\n",
    "        \n",
    "        # check if the the person got the correct answer\n",
    "        if ... == ...:\n",
    "            \n",
    "            # add the number of points they earned for the correct response\n",
    "            ...\n",
    "            \n",
    "    # append the score to the list of scores\n",
    "    ...\n",
    "    \n",
    "# add the score to the original dataframe using df['scores'] = scores\n",
    "...  \n",
    "            "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can find the winner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Joshua Agar'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use df['scores'] and convert to numpy using .to_numpy() method\n",
    "# use the .argsort() method to find the sorted index\n",
    "# then flip the array using [::-1] \n",
    "...\n",
    "\n",
    "# Use df.iloc[ind[0]] to get the row of winner.\n",
    "# Then index the dataframe to get the winners name\n",
    "..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ENGR_131",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "775f42d2c624786ce087f304b32550a3a398124b7164551d1aea823130207773"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}